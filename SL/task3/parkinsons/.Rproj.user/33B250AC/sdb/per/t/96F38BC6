{
    "contents" : "---\ntitle: \"parkinsons\"\nauthor: \"Karim Amanov\"\ndate: \"9 января 2015 г.\"\noutput: html_document\n---\n\n\n```{r}\nlibrary(MASS)\nlibrary(lattice)\nlibrary(latticeExtra)\nlibrary(ISLR)\nlibrary(e1071)\nlibrary(nnet)\noptions(warn=-1)\n\n```\n\nЗагружаем данные\n```{r}\nparkinsons <- read.csv(\"parkinsons.csv\", comment.char = \"#\")\n\n```\nДля начала выкинем столбец names и будем анализировать данные независимо\n```{r}\nparkinsons$name <- NULL\n```\nПостроим различные графики\n\n```{r}\nlibrary(corrplot)\ncorrplot(cor(parkinsons))\n```\n\nМожем наблюдать сильную зависимость многих параметров. \n\n```{r}\nmarginal.plot(parkinsons)\n```\n\nСразу уберем MDVP.Jitter.Abs, потому что есть значение этого параметра в процентах. Еще можно будет попробовать прологарифмировать некторые параметры, чтобы распределния стали более симметричными\n\n```{r}\nparkinsons$MDVP.Jitter.Abs <- NULL\nmarginal.plot(log(subset(parkinsons, select = c(-status, -spread1, -spread2, -MDVP.Fo.Hz., -MDVP.Fhi.Hz.))))\n\n```\n\n```{r}\nparkinsons$status <- factor(parkinsons$status, labels = c(\"No\",\"Yes\"))\ncontrasts(parkinsons$status)\nmarginal.plot(parkinsons, data = parkinsons, groups = status,,auto.key = list(lines = TRUE, title =\"Status\",cex.title = 1))\n```\n\nПодготовим данные и перейдем к построению модели.\n```{r}\ntrain.idx <- sample(nrow(parkinsons), size = nrow(parkinsons) * 0.66)\nparkinsons.train <- parkinsons[train.idx, ]\nparkinsons.test <- parkinsons[-train.idx, ]\n```\n\n***Logistic Regression***\n```{r}\nbuild_and_test_logistic <- function(formula) {\n  simple.predict.glm <- function(x, newdata, ...) {\n  response <- predict(x, newdata, type = \"response\", ...)\n  factor(levels(x$model[, 1])[1 + as.integer(response > 0.5)]) \n  }\n  model <- glm(formula , data = parkinsons.train, family = binomial(link = \"logit\"))\n  print(model)\n\n  print(tune(glm, formula, family = binomial(link = \"logit\"), data = parkinsons, predict.func = simple.predict.glm, tunecontrol = tune.control(sampling = \"cross\",cross = 10)))\n  \n  my.predicted <- simple.predict.glm(model, newdata=parkinsons.test)\n  print(table(predicted = my.predicted, actual = parkinsons.test$status))\n  print(mean(my.predicted != parkinsons.test$status))\n  return (model)\n}\nglm.fit <-build_and_test_logistic(status ~ .)\n```\n\nПопросим stepAIC выбрать нужные параметры\n\n```{r}\nmodel.aic <- stepAIC(glm.fit)\nm <- build_and_test_logistic(as.formula(model.aic))\n```\n\nТеперь попробуем другие методы с этими параметрами\n\n*LDA*\n```{r}\nbuild_and_test_lda <- function(formula) {\n  model <- lda(formula , data = parkinsons.train)\n  print(model)\n\n  print(tune(lda, formula, data = parkinsons, predict.func = function(...) predict(...)$class, tunecontrol = tune.control(sampling = \"cross\",cross = 10)))\n  \n  my.predicted <- predict(model, parkinsons.test)\n  print(table(predicted = my.predicted$class, actual = parkinsons.test$status))\n  print(mean(my.predicted$class != parkinsons.test$status))\n}\nbuild_and_test_lda(as.formula(model.aic))\n```\nНемного улучшили\n\n*naive bayes*\n```{r}\nbuild_and_test_bayes <- function(formula) {\n  model <- naiveBayes(formula , data = parkinsons.train)\n  print(model)\n\n  print(tune(naiveBayes, formula, data = parkinsons, predict.func = function(...) predict(...), tunecontrol = tune.control(sampling = \"cross\",cross = 10)))\n  \n  my.predicted <- predict(model, parkinsons.test)\n  print(table(predicted = my.predicted, actual = parkinsons.test$status))\n  print(mean(my.predicted != parkinsons.test$status))\n}\n\nbuild_and_test_bayes(as.formula(model.aic))\n```\nНе очень.\n\n*multinomial regression*\n```{r}\nbuild_and_test_multinom <- function(formula) {\n  model <- multinom(formula , data = parkinsons.train, trace = FALSE, maxit = 4000)\n  print(model)\n\n  print(tune(multinom, formula, data = parkinsons, trace = FALSE, maxit = 4000, predict.func = function(...) predict(...), tunecontrol = tune.control(sampling = \"cross\",cross = 10)))\n  \n  my.predicted <- predict(model, parkinsons.test)\n  print(table(predicted = my.predicted, actual = parkinsons.test$status))\n  print(mean(my.predicted != parkinsons.test$status))\n}\nbuild_and_test_multinom(as.formula(model.aic))\n```\n\nМодель построенная методом LDA показала себя лучше всех, на ней пока и остановимся.\n\nДавайте теперь сгруппируем данные по пациентам (возьмем среднее по соответствующему признаку) и опять попробуем построить модель\n```{r}\nparkinsons <- read.csv(\"parkinsons.csv\", comment.char = \"#\")\nparkinsons$name <- substr(parkinsons$name,1, 13)\nparkinsons <- aggregate(parkinsons, by=list(parkinsons$name), FUN=mean)\nparkinsons$Group.1 <- NULL\nparkinsons$name <- NULL\nparkinsons$status <- factor(parkinsons$status, labels = c(\"No\",\"Yes\"))\ndim(parkinsons)\n\ntrain.idx <- sample(nrow(parkinsons), size = nrow(parkinsons) * 0.66)\nparkinsons.train <- parkinsons[train.idx, ]\nparkinsons.test <- parkinsons[-train.idx, ]\nmodel.group.glm <-build_and_test_logistic(status ~ .)\n```\n\nПосмотрим что теперь нам скажет AIC\n```{r}\nmodel.group.aic <- stepAIC(model.group.glm)\nm <- build_and_test_logistic(as.formula(model.group.aic))\n\n```\n\nПопробуем другими методами\n```{r}\nbuild_and_test_multinom(as.formula(model.group.aic))\nbuild_and_test_bayes(as.formula(model.group.aic))\nbuild_and_test_lda(as.formula(model.group.aic))\n```\nмодель Lda опять оказалась лучшей. Также она немного превзошла модель, выбранную для несгруппированных данных. Поэтому остановим свой выбор на этой модели.\n\nДавайте теперь построим ROC кривые\n\n```{r}\nlibrary(ROCR)\nROC <- function(predicted, actual, ...) {\n  pred <- prediction(predicted, as.numeric(actual))\n  roc <- performance(pred, measure = \"tpr\",\n  x.measure = \"fpr\", ...)\n  roc\n}\n\nAUC <- function(predicted, actual, ...) {\n  pred <- prediction(predicted, as.numeric(actual))\n  perf <- performance(pred, measure = \"auc\", ...)\n  perf@y.values[[1]]\n}\nplotRoc <- function(m) {\n  roc <- ROC(predict(m, parkinsons), parkinsons$status)\n  plot(roc)\n}\nplotRoc(model.group.aic)\nAUC(predict(model.group.aic, parkinsons), parkinsons$status)\nplotRoc(model.aic)\nAUC(predict(model.aic, parkinsons), parkinsons$status)\n\n```\n\nROC кривые выглядят хорошо",
    "created" : 1420761534131.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2066524879",
    "id" : "96F38BC6",
    "lastKnownWriteTime" : 1420857285,
    "path" : "~/Spbau/SL/task3/parkinsons/parkinsons_report_amanov.Rmd",
    "project_path" : "parkinsons_report_amanov.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}